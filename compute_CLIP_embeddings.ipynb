{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "compute CLIP embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qBVz1Cnngwd"
      },
      "source": [
        "%%capture\n",
        "!pip install -q transformers >/dev/null\n",
        "\n",
        "import os\n",
        "import time\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from multiprocessing.dummy import Pool\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "\n",
        "def compute_image_embeddings(list_of_images):\n",
        "  return model.get_image_features(**processor(images=list_of_images, return_tensors=\"pt\", padding=True))\n",
        "\n",
        "def load_image(path, same_height=False):\n",
        "  im = Image.open(path)\n",
        "  if im.mode != 'RGB':\n",
        "    im = im.convert('RGB')\n",
        "  if same_height:\n",
        "    ratio = 224/im.size[1]\n",
        "    return im.resize((int(im.size[0]*ratio), int(im.size[1]*ratio)))    \n",
        "  else:\n",
        "    ratio = 224/min(im.size)\n",
        "    return im.resize((int(im.size[0]*ratio), int(im.size[1]*ratio)))\n",
        "\n",
        "def fetch_url(url_filename):\n",
        "  url, filename = url_filename\n",
        "  urllib.request.urlretrieve(url, filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7a-g-Pw-19H"
      },
      "source": [
        "max_n_parallel = 20\n",
        "latency = 2 # idle duration to reduce the download rate for the images\n",
        "\n",
        "for dataset in ['', '2']:\n",
        "  df = pd.read_csv(f'data{dataset}.csv')\n",
        "  length = len(df)\n",
        "\n",
        "  try:\n",
        "    image_embeddings = np.load(f\"embeddings{dataset}.npy\")\n",
        "    i = image_embeddings.shape[0]\n",
        "  except FileNotFoundError:\n",
        "    image_embeddings, i = None, 0\n",
        "\n",
        "  while i < length:\n",
        "    for f in os.listdir():\n",
        "      if '.jpeg' in f:\n",
        "        os.remove(f)\n",
        "\n",
        "    n_parallel = min(max_n_parallel, length - i)\n",
        "    url_filename_list = [(df.iloc[i + j]['path'], str(i + j) + '.jpeg') for j in range(n_parallel)]\n",
        "    _ = Pool(n_parallel).map(fetch_url, url_filename_list)\n",
        "    batch_embeddings = compute_image_embeddings([load_image(str(i + j) + '.jpeg') for j in range(n_parallel)]).detach().numpy()\n",
        "\n",
        "    if image_embeddings is None:\n",
        "      image_embeddings = batch_embeddings\n",
        "    else:\n",
        "      image_embeddings = np.vstack((image_embeddings, batch_embeddings))\n",
        "\n",
        "    i = image_embeddings.shape[0]\n",
        "    time.sleep(latency)\n",
        "    if i % 100 == 0:\n",
        "      np.save(f\"embeddings{dataset}.npy\", image_embeddings)\n",
        "      print(i)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}